{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>LACSS is a deep-learning model for single-cell segmentation from microscopy images.</p>"},{"location":"#why-lacss","title":"Why LACSS?","text":"<p>LACSS is designed to utilize point labels for model training. You have three options:</p> Method Data(left) / Label(right) Point Point + Mask Segmentation <p>You can also combined these labels in any way you want.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#linux","title":"Linux","text":"<pre><code># check nvidia driver version &gt;= 525.60.13\ncat /proc/driver/nvidia/version\n\n# check python version is 3.10 or higher\npython --verison\n\npip install lacss\n</code></pre>"},{"location":"install/#windows","title":"Windows","text":"<ul> <li>Make sure nividia driver version &gt;= 452.39, following Nvidia-FAQ</li> <li>Make sure you have a python version &gt;= 3.10 (python --version)</li> <li>Install CUDA and cudnn following Nivida's step-by-step instructions Nvidai-cudnn</li> <li>Download jaxlib wheel from jaxlib. The file name specifies versions of cuda, cudnn and python. Make sure it matches your setup.</li> <li>Install lacss and dependencies into your virtual environment</li> </ul> <pre><code>pip install &lt;downloaded jaxlib wheel file&gt;\npip install jax==&lt;jaxlib version&gt; flax==0.7.2\npip install lacss\n</code></pre>"},{"location":"api/data/","title":"lacss.data","text":"<p>Lacss Data Pipeline API</p>"},{"location":"api/data/#tf-dataset","title":"TF Dataset","text":""},{"location":"api/data/#lacss.data.generator.dataset_from_coco_annotations","title":"<code>dataset_from_coco_annotations(annotation_file, image_path, image_shape=[None, None, 3], mask_shape=[48, 48])</code>","text":"<p>Obtaining a tensowflow dataset from coco annotations. See coco_generator_full()</p> <p>Parameters:</p> Name Type Description Default <code>annotation_file</code> <code>str</code> <p>Path to coco annotation files</p> required <code>image_path</code> <code>str</code> <p>Path to image directory</p> required <code>image_shape</code> <code>tuple</code> <p>The expect image shapes. Use None to represent variable dimensions.</p> <code>[None, None, 3]</code> <code>mask_shape</code> <code>tuple</code> <p>If supplied, all the instance segmentations will be croped and resized to the specifed size. Otherwise, the segmentations are uncropped (in original image size)</p> <code>[48, 48]</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>A tensorflow dataset.</p>"},{"location":"api/data/#lacss.data.generator.dataset_from_simple_annotations","title":"<code>dataset_from_simple_annotations(annotation_file, image_path, image_shape=[None, None, 1], has_binary_mask=False)</code>","text":"<p>Obtaining a tensowflow dataset from simple annotatiion. See simple_generator()</p> <p>Parameters:</p> Name Type Description Default <code>annotation_file</code> <code>str</code> <p>Path to the json format annotation file.</p> required <code>image_path</code> <code>str</code> <p>Path to the image directory.</p> required <code>image_shape</code> <code>Sequence[int | None]</code> <p>The expect image shapes. Use None to represent variable dimensions.</p> <code>[None, None, 1]</code> <code>has_binary_mask</code> <code>bool</code> <p>whether the annotation specific a binary mask</p> <code>False</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>A tensorflow dataset object</p>"},{"location":"api/data/#lacss.data.generator.dataset_from_img_mask_pairs","title":"<code>dataset_from_img_mask_pairs(imgfiles, maskfiles, *, image_shape=[None, None, 3], generate_masks=False, mask_shape=[48, 48])</code>","text":"<p>Obtaining a tensowflow dataset from image/label pairs.         See img_mask_pair_generator()</p> <p>Parameters:</p> Name Type Description Default <code>imgfiles</code> <code>Sequence[str | Path]</code> <p>List of file pathes to input image file.</p> required <code>maskfiles</code> <code>Sequence[str | Path]</code> <p>List of file pathes to label image file.</p> required <p>Other Parameters:</p> Name Type Description <code>image_shape</code> <code>Sequence[int | None]</code> <p>The expect image shapes. Use None to represent variable dimensions.</p> <code>generate_masks</code> <code>bool</code> <p>Whether to convert label images to indiviudal instance masks. This should be True if your data augmentation pipeline include rescaling ops or cropping ops., becasue these ops does not recompute the label image.</p> <code>mask_shape</code> <code>tuple[int, int]</code> <p>Only when generate_mask=True. The resolution of the generated masks.</p> <p>Returns:</p> Type Description <code>Dataset</code> <p>A tensorflow dataset object</p>"},{"location":"api/data/#data-augmentation","title":"Data augmentation","text":"<p>The augmentation functions for TF Dataset inputs.</p>"},{"location":"api/data/#lacss.data.augment.crop_to_roi","title":"<code>crop_to_roi(inputs, *, roi, area_ratio_threshold=1.0, clip_boxes=True, p=1.0)</code>","text":"<p>Crop image to bounding-box ROI</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> <li>masks</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>roi</code> <code>tuple[int, ...]</code> <p>Rectangle roi in yxyx format</p> <code>area_ratio_threshold</code> <code>float</code> <p>remove instances if the bbox's relative remaining area is below this threshold</p> <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.flip_left_right","title":"<code>flip_left_right(inputs, *, p=1.0)</code>","text":"<p>Flip image left-right</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.flip_top_bottom","title":"<code>flip_top_bottom(inputs, *, p=1.0)</code>","text":"<p>Flip image up-down</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.flip_up_down","title":"<code>flip_up_down(inputs, *, p=1.0)</code>","text":"<p>Flip image up-down</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.pad","title":"<code>pad(inputs, *, paddings, constant_values=0, p=1.0)</code>","text":"<p>Pad image and labels.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>paddings</code> <code>int | tuple[int, ...]</code> <p>either a tuple or a single value. If latter, use the same padding for both x and y axis</p> <code>constant_values</code> <code>float</code> <p>the value to fill the padded area</p> <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.pad_to_size","title":"<code>pad_to_size(inputs, *, target_size, constant_values=0, p=1.0)</code>","text":"<p>Pad image and labels to a target size. Padding is applied so that the orginal scene is centered in the output.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>target_size</code> <code>int | tuple[int, ...]</code> <p>target image size</p> <code>constant_values</code> <code>float</code> <p>the value to fill the padded area</p> <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.random_crop","title":"<code>random_crop(inputs, *, target_size, area_ratio_threshold=1.0, clip_boxes=True, p=1.0)</code>","text":"<p>Random crop to a set target size</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> <li>masks</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>target_size</code> <code>int | tuple[int, ...]</code> <p>the target size</p> <code>area_ratio_threshold</code> <code>float</code> <p>remove instances if the bbox's relative remaining area is below this threshold</p> <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.random_crop_or_pad","title":"<code>random_crop_or_pad(inputs, *, target_size, constant_values=0, area_ratio_threshold=1.0, clip_boxes=True, p=1.0)</code>","text":"<p>Random crop or pad image to specified target_size.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> <li>masks</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>target_size</code> <code>tuple[int, int]</code> <p>target size</p> <code>constant_values</code> <code>float</code> <p>the value to fill the padded area</p> <code>area_ratio_threshold</code> <code>float</code> <p>remove instances if the bbox's relative remaining area is below this threshold</p> <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.random_resize","title":"<code>random_resize(inputs, *, scaling, keep_aspect_ratio=False, p=1.0)</code>","text":"<p>Resize image by a random amount</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>scaling</code> <code>float | tuple[float, float]</code> <p>range of scale, e.g, [0.8, 1.5].</p> <code>keep_aspect_ratio</code> <code>bool</code> <p>Whether to scale x/y the same amount.</p> <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#lacss.data.augment.resize","title":"<code>resize(inputs, *, target_size, p=1.0)</code>","text":"<p>Resize image and labels</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>data from TF dataset. Affected elements are:</p> <ul> <li>image</li> <li>image_mask</li> <li>centroids</li> <li>bboxes</li> </ul> required <p>Other Parameters:</p> Name Type Description <code>target_size</code> <code>tuple[int, int]</code> <p>target size</p> <code>p</code> <code>float</code> <p>probability of applying transformation</p>"},{"location":"api/data/#python-generator","title":"Python generator","text":""},{"location":"api/data/#lacss.data.generator.coco_generator_full","title":"<code>coco_generator_full(annotation_file, image_path, mask_shape=None)</code>","text":"<p>A generator function to produce coco-annotated data</p> <p>Parameters:</p> Name Type Description Default <code>annotation_file</code> <code>str</code> <p>Path to coco annotation files</p> required <code>image_path</code> <code>str</code> <p>Path to image directory</p> required <code>mask_shape</code> <code>Optional[tuple[int, int]]</code> <p>If supplied, all the instance segmentations will be croped and resized to the specifed size. Otherwise, the segmentations are uncropped (in original image size)</p> <code>None</code> <p>Yields:</p> Type Description <code>dict</code> <p>A data dictionary with thse keys:</p> <ul> <li>id: data id</li> <li>filename: image filename</li> <li>image: an array [H, W, C]</li> <li>masks: segmentation masks. [N, H, W] or [N,] + mask_shape</li> <li>centroids: yx format.</li> <li>bboxes: y0x0y1x1 format.</li> <li>label: an array [H, W] representing pixel labels of all instances.</li> </ul>"},{"location":"api/data/#lacss.data.generator.simple_generator","title":"<code>simple_generator(annotation_file, image_path)</code>","text":"<p>A simple generator function to produce image data labeled with points and image-level segmentaion.</p> <p>Parameters:</p> Name Type Description Default <code>annotation_file</code> <code>str</code> <p>Path to the json format annotation file.</p> required <code>image_path</code> <code>str</code> <p>Path to the image directory.</p> required <p>Yields:</p> Type Description <code>dict</code> <p>A data dictionary with thse keys:</p> <ul> <li>img_id: data id</li> <li>image: an array [H, W, C]</li> <li>centroids: yx format.</li> <li>image_mask: segmentation masks for the image. [H, W]</li> </ul>"},{"location":"api/data/#lacss.data.generator.img_mask_pair_generator","title":"<code>img_mask_pair_generator(imgfiles, maskfiles, *, mask_shape=None)</code>","text":"<p>A generator function to produce image data labeled with segmentation labels.     In this case, one has paired input images and label images as files on disk.</p> <p>Parameters:</p> Name Type Description Default <code>imgfiles</code> <code>Sequence[str | Path]</code> <p>List of file pathes to input image file.</p> required <code>maskfiles</code> <code>Sequence[str | Path]</code> <p>List of file pathes to label image file.</p> required <p>Other Parameters:</p> Name Type Description <code>mask_shape</code> <code>tuple[int] | None</code> <p>if not None, generate cropped masks at specified shape</p> <p>Yields:</p> Type Description <code>dict</code> <p>A data dictionary with thse keys:</p> <ul> <li>img_id: data id</li> <li>image: an array [H, W, C]</li> <li>centroids: yx format.</li> <li>bboxes: y0x0y1x1 format.</li> <li>label: an array [H, W] representing pixel labels of all instances.</li> <li>masks: if mask_shape is not None</li> </ul>"},{"location":"api/deploy/","title":"lacss.deploy","text":"<p>Attributes:</p> Name Type Description <code>model_urls</code> <p>URLs for build-in pretrain models. e.g model_urls[\"default\"].</p>"},{"location":"api/deploy/#lacss.deploy.predict.Predictor","title":"<code>Predictor</code>","text":"<p>Main class interface for model deployment. This is the only class you need if you don't train your own model</p> <p>Examples:</p> <p>The most common use case is to use a build-in pretrained model.</p> <pre><code>import lacss.deploy\n\n# look up the url of a build-in mode\nurl = lacss.deploy.model_urls[\"default\"]\n\n# create the predictor instance\npredictor = lacss.deploy.Predictor(url)\n\n# make a prediction\nlabel = predictor.predict(image)\n</code></pre> <p>Attributes:</p> Name Type Description <code>module</code> <code>Module</code> <p>The underlying FLAX module</p> <code>params</code> <code>dict</code> <p>Model weights.</p>"},{"location":"api/deploy/#lacss.deploy.predict.Predictor.__init__","title":"<code>__init__(url)</code>","text":"<p>Construct Predictor</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | tuple[Module, dict]</code> <p>A URL or local path to the saved model. URLs for build-in pretrained models can be found in lacss.deploy.model_urls</p> required"},{"location":"api/deploy/#lacss.deploy.predict.Predictor.predict","title":"<code>predict(image, *, output_type='label', reshape_to=None, min_area=0, score_threshold=0.5, segmentation_threshold=0.5, nms_iou=1, normalize=True, remove_out_of_bound=None)</code>","text":"<p>Predict segmentation.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ArrayLike</code> <p>A ndarray of (h,w,c) or (d,h,w,c) format. c must be 1-3</p> required <p>Other Parameters:</p> Name Type Description <code>output_type</code> <code>str</code> <p>\"label\" | \"contour\" | \"bbox\"</p> <code>reshape_to</code> <code>int | tuple[int] | None</code> <p>If not None, the input image will be resized internally before send to the model. The results will be resized back to the scale of the orginal input image.</p> <code>min_area</code> <code>float</code> <p>Minimum area of a valid prediction.</p> <code>score_threshold</code> <code>float</code> <p>Min score needed to be included in the output.</p> <code>segmentation_threshold</code> <code>float</code> <p>Threshold value for segmentation</p> <code>nms_iou</code> <code>float</code> <p>IOU threshold value for non-max-supression post-processing</p> <p>Returns:</p> Type Description <code>dict</code> <p>For \"label\" output:</p> <ul> <li>pred_scores: The prediction scores of each instance.</li> <li>pred_label: a 2D image label. 0 is background.</li> </ul> <code>dict</code> <p>For \"contour\" output:</p> <ul> <li>pred_scores: The prediction scores of each instance.</li> <li>pred_contours: a list of polygon arrays in x-y format.</li> </ul> <code>dict</code> <p>For \"bbox\" output (ie MaskRCNN):</p> <ul> <li>pred_scores: The prediction scores of each instance.</li> <li>pred_bboxes: The bounding-boxes of detected instances in y0x0y1x1 format</li> <li>pred_masks:  A 3d array representing (rescaled) segmentation mask within bboxes</li> </ul>"},{"location":"api/deploy/#lacss.deploy.predict.Predictor.predict_on_large_image","title":"<code>predict_on_large_image(image, *, reshape_to=None, gs=None, ss=None, nms_iou=0.0, score_threshold=0.5, segmentation_threshold=0.5, min_area=0, min_cells_per_patch=0, output_type='label')</code>","text":"<p>Make prediction on very large image by dividing into a grid.</p> <p>Direct model prediction on large image may cause out-of-memory error. This method divided the large image to smaller grid and then stitch the results to form the complete prediction.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ArrayLike</code> <p>An image with (H, W, C) format.</p> required <code>gs</code> <code>int | None</code> <p>An int value. Grid size of the computation.</p> <code>None</code> <code>ss</code> <code>int | None</code> <p>An int value of stepping size. Must be small than gs to produce valid results.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>min_area</code> <code>float</code> <p>Minimum area of a valid prediction.</p> <code>score_threshold</code> <code>float</code> <p>Min score needed to be included in the output.</p> <code>segmentation_threshold</code> <code>float</code> <p>Threshold value for segmentation.</p> <code>nms_iou</code> <code>float</code> <p>IOU threshold value for non-max-supression durint post-processing</p> <p>Returns:</p> Type Description <code>dict</code> <ul> <li>pred_scores: The prediction scores of each instance.</li> </ul> <code>dict</code> <ul> <li>pred_bboxes: The bounding-boxes of detected instances in y0x0y1x1 format</li> </ul> <code>dict</code> <ul> <li>pred_masks: A 3d array representing segmentation within bboxes</li> </ul>"},{"location":"api/losses/","title":"lacss.losses","text":""},{"location":"api/losses/#lacss.losses.instance.self_supervised_instance_loss","title":"<code>self_supervised_instance_loss(batch, prediction)</code>","text":"<p>Unsupervised instance loss</p>"},{"location":"api/losses/#lacss.losses.instance.supervised_instance_loss","title":"<code>supervised_instance_loss(batch, prediction)</code>","text":"<p>LACSS instance loss, supervised with segmentation label</p>"},{"location":"api/losses/#lacss.losses.instance.weakly_supervised_instance_loss","title":"<code>weakly_supervised_instance_loss(batch, prediction)</code>","text":"<p>Instance loss supervised by image mask instead of instance masks</p>"},{"location":"api/losses/#lacss.losses.auxiliary.aux_size_loss","title":"<code>aux_size_loss(batch, prediction, *, weight=0.01)</code>","text":"<p>Auxillary loss to prevent model collapse</p>"},{"location":"api/losses/#lacss.losses.auxiliary.cks_boundry_loss","title":"<code>cks_boundry_loss(batch, prediction)</code>","text":"<p>Cell border prediction consistency loss</p>"},{"location":"api/losses/#lacss.losses.auxiliary.cks_segmentation_loss","title":"<code>cks_segmentation_loss(batch, prediction, *, offset_sigma=10.0, offset_scale=2.0)</code>","text":"<p>Image segmentation consistenct loss for the collaboraor model</p>"},{"location":"api/modules/","title":"lacss.modules","text":""},{"location":"api/modules/#lacss.modules.Lacss","title":"<code>lacss.modules.Lacss</code>","text":"<p>               Bases: <code>Module</code>, <code>DefaultUnpicklerMixin</code></p> <p>Main class for LACSS model</p> <p>Attributes:</p> Name Type Description <code>backbone</code> <code>Module</code> <p>CNN backbone</p> <code>detector</code> <code>Module</code> <p>detection head to predict cell locations</p> <code>segmentor</code> <code>Module | None</code> <p>The segmentation head</p>"},{"location":"api/modules/#lacss.modules.Lacss.__call__","title":"<code>__call__(image, *, image_mask=None, video_refs=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image</code> <code>ArrayLike</code> <p>[H, W, C] or [D, H, W, C]</p> required <p>Returns:     a dict of model outputs</p>"},{"location":"api/modules/#lacss.modules.LPN","title":"<code>lacss.modules.LPN</code>","text":"<p>               Bases: <code>Module</code>, <code>DefaultUnpicklerMixin</code></p> <p>Location detection head</p> <p>Attributes:</p> Name Type Description <code>nms_threshold</code> <code>float</code> <p>non-max-supression threshold, if performing nms on detected locations.</p> <code>pre_nms_topk</code> <code>int</code> <p>max number of detections to be processed regardless of nms, ignored if negative</p> <code>max_output</code> <code>int</code> <p>number of detection outputs</p>"},{"location":"api/modules/#lacss.modules.Segmentor","title":"<code>lacss.modules.Segmentor</code>","text":"<p>               Bases: <code>Module</code>, <code>DefaultUnpicklerMixin</code></p> <p>LACSS segmentation head.</p> <p>Attributes:</p> Name Type Description <code>n_cls</code> <p>num of classes</p> <code>feature_scale</code> <code>int</code> <p>the spatail scale of the feature level</p> <code>instance_crop_size</code> <code>int</code> <p>Crop size for segmentation.</p> <code>pos_emb_shape</code> <code>Sequence[int]</code> <p>Dim of the learned position encoder.</p>"},{"location":"api/modules/#lacss.modules.Segmentor.__call__","title":"<code>__call__(feature, locations)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>features</code> <p>[H, W, C] features from the backbone.</p> required <code>locations</code> <code>ArrayLike</code> <p>[N, 2]</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A nested dictionary of values representing segmentation outputs. * segmentor/logits: all segment logits * predictions/segmentations: logits of designated class [N, D, ps, ps] * predictions/segmentation_y0_coord: y coord of patch top-left corner [N] * predictions/segmentation_x0_coord: x coord of patch top-left corner [N] * predictions/segmentation_is_valid: mask for valid patches [N]</p>"},{"location":"api/ops/","title":"lacss.ops","text":"<p>Ops on bounding-boxes</p> <p>All functions here are degisned to work as either a numpy op or a jax op depending on the data type of the input.</p> <p>Various functions deals with segmentation pathces</p> <p>All functions here takes unbatched input. Use vmap to convert to batched data</p>"},{"location":"api/ops/#lacss.ops.boxes.box_area","title":"<code>box_area(box)</code>","text":"<p>Computes area of boxes. Args:   box: a float Tensor with [..., N, 2d].</p> <p>Returns:</p> Type Description <code>ArrayLike</code> <p>a float Tensor with [..., N]</p>"},{"location":"api/ops/#lacss.ops.boxes.box_intersection","title":"<code>box_intersection(gt_boxes, boxes)</code>","text":"<p>Compute pairwise intersection areas between boxes.</p> <p>Parameters:</p> Name Type Description Default <code>gt_boxes</code> <code>ArrayLike</code> <p>[..., N, 2d]</p> required <code>boxes</code> <code>ArrayLike</code> <p>[..., M, 2d]</p> required <p>Returns:</p> Type Description <code>ArrayLike</code> <p>a float Tensor with shape [..., N, M] representing pairwise intersections.</p>"},{"location":"api/ops/#lacss.ops.boxes.box_iou_similarity","title":"<code>box_iou_similarity(gt_boxes, boxes)</code>","text":"<p>Computes pairwise intersection-over-union between box collections.</p> <p>Parameters:</p> Name Type Description Default <code>gt_boxes</code> <code>ArrayLike</code> <p>a float Tensor with [..., N, 2d].</p> required <code>boxes</code> <code>ArrayLike</code> <p>a float Tensor with [..., M, 2d].</p> required <p>Returns:</p> Type Description <code>ArrayLike</code> <p>a Tensor with shape [..., N, M] representing pairwise iou scores.</p>"},{"location":"api/ops/#lacss.ops.boxes.distance_iou_loss","title":"<code>distance_iou_loss(gt_boxes, boxes)</code>","text":"<p>Loss_distance_iou = 1 - IoU +  ho2(B, B_GT) / c2 The correction term is \"distance_sq between box center\" / \"distance_sq of enclosing box cornor\"</p> <p>Parameters:</p> Name Type Description Default <code>gt_boxes</code> <code>ArrayLike</code> <p>a float Tensor with [..., N, 2d].</p> required <code>boxes</code> <code>ArrayLike</code> <p>a float Tensor with [..., N, 2d].</p> required <p>Returns:</p> Type Description <code>ArrayLike</code> <p>a Tensor with shape [..., N] representing pairwise loss.</p>"},{"location":"api/ops/#lacss.ops.boxes.distance_similarity","title":"<code>distance_similarity(pred_locations, gt_locations)</code>","text":"<p>Compute distance similarity matrix</p> <pre><code>pairwise similarity = 1 / distance ^2\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>pred_locations</code> <code>ArrayLike</code> <p>[N, d] use -1 to mask out invalid locations</p> required <code>gt_locations</code> <code>ArrayLike</code> <p>[K, d] use -1 to mask out invalid locations</p> required <p>Returns:</p> Name Type Description <code>similarity_matrix</code> <code>Array</code> <p>[N, k]</p>"},{"location":"api/ops/#lacss.ops.boxes.feature_matching","title":"<code>feature_matching(features_a, features_b, threshold, *, similarity_fn=None)</code>","text":"<p>Match predicted location to gt locations</p> <p>Parameters:</p> Name Type Description Default <code>features_a</code> <code>ArrayLike</code> <p>r [N, d], points or bboxes</p> required <code>features_b</code> <code>ArrayLike</code> <p>[K, d], points or bboxes</p> required <code>threshold</code> <code>float</code> <p>float. Min similarity score for match</p> required <p>Other Parameters:</p> Name Type Description <code>similarity_fn</code> <p>optional custom function for computing similarity score   fn(feautes_a, feature_b) -&gt; similarity matrix</p> <p>Returns:</p> Name Type Description <code>matches</code> <code>Array</code> <p>[N], indices of the matches row in b </p> <code>indicators</code> <code>Array</code> <p>[N] bool</p>"},{"location":"api/ops/#lacss.ops.boxes.generalized_iou_loss","title":"<code>generalized_iou_loss(gt_boxes, boxes)</code>","text":"<p>Loss_GIoU = 1 - IoU + |C - B union B_GT| / |C| where C is the smallest enclosing box for both B and B_GT. The resulting value has a gradient  for non-overlapping boxes. See  Zheng et al. [AAAI 2020] </p> <p>Parameters:</p> Name Type Description Default <code>gt_boxes</code> <code>ArrayLike</code> <p>a float Tensor with [..., N, 2d].</p> required <code>boxes</code> <code>ArrayLike</code> <p>a float Tensor with [..., N, 2d].</p> required <p>Returns:</p> Type Description <code>ArrayLike</code> <p>a Tensor with shape [..., N] representing pairwise loss.</p>"},{"location":"api/ops/#lacss.ops.boxes.iou_loss","title":"<code>iou_loss(gt_boxes, boxes)</code>","text":"<p>IOU loss = 1 - IOU Args:   gt_boxes: a float Tensor with [..., N, 2d].   boxes: a float Tensor with [..., N, 2d].</p> <p>Returns:</p> Type Description <code>ArrayLike</code> <p>a Tensor with shape [..., N] representing pairwise loss.</p>"},{"location":"api/ops/#lacss.ops.boxes.match_and_replace","title":"<code>match_and_replace(gt_features, pred_features, threshold, *, similarity_fn=None)</code>","text":"<p>replacing gt_locations with pred_locations if the close enough 1. Each pred_location is matched to the closest gt_location 2. For each gt_location, pick the matched pred_location with highest score 3. if the picked pred_location is within threshold distance, replace the gt_location with the pred_location</p>"},{"location":"api/ops/#lacss.ops.boxes.yxhw_iou_similarity","title":"<code>yxhw_iou_similarity(yxhw_a, yxhw_b)</code>","text":"<p>Computes pairwise IOU on bbox in yxhw format</p> <p>Parameters:</p> Name Type Description Default <code>gt_boxes</code> <p>a float Tensor with [..., N, 2d].</p> required <code>boxes</code> <p>a float Tensor with [..., M, 2d].</p> required <p>Returns:</p> Type Description <p>a Tensor with shape [..., N, M] representing pairwise iou scores.</p>"},{"location":"api/ops/#lacss.ops.image.sorbel_edges","title":"<code>sorbel_edges(images)</code>","text":"<p>Returns a tensor holding Sobel edge maps.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; image = random.uniform(key, shape=[3, 28, 28])\n&gt;&gt;&gt; sobel = sobel_edges(image)\n&gt;&gt;&gt; sobel_y = sobel[0, :, :, :] # sobel in y-direction\n&gt;&gt;&gt; sobel_x = sobel[1, :, :, :] # sobel in x-direction\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>image</code> <p>[n, h, w]</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Tensor holding edge maps for each channel. [2, n, h, w]</p>"},{"location":"api/ops/#lacss.ops.image.sorbel_edges_3d","title":"<code>sorbel_edges_3d(images)</code>","text":"<p>Returns a tensor holding Sobel edge maps in 3d.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>ArrayLike</code> <p>[n, d, h, w]</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Tensor holding edge maps for each channel. [3, n, d, h, w]</p>"},{"location":"api/ops/#lacss.ops.image.sub_pixel_crop_and_resize","title":"<code>sub_pixel_crop_and_resize(img, bbox, output_shape, out_of_bound_value=0)</code>","text":"<p>Retrieve image values of a bbox. Resize output to output_shape. Used for ROI-Align.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ArrayLike</code> <p>Array of shape [H, W, ...] (2D) or [D, H, W, ...] (3D)</p> required <code>bbox</code> <code>ArrayLike</code> <p>[y0, x0, y1, x1] (2D) or [z0, y0, x0, z1, y1, x1] (3D)</p> required <code>output_shape</code> <code>tuple[int]</code> <p>[h, w] (2D) or [d, h, w] (3D)</p> required <code>out_of_bound_value</code> <code>float</code> <p>optional float constant, defualt 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>values</code> <code>Array</code> <p>[h, w, ...] or [d, h, w, ...]</p>"},{"location":"api/ops/#lacss.ops.image.sub_pixel_samples","title":"<code>sub_pixel_samples(img, locs, out_of_bound_value=0, edge_indexing=False)</code>","text":"<p>Retrieve image values as non-integer locations by interpolation</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ArrayLike</code> <p>Array of shape [D1,D2,..,Dk, ...]</p> required <code>locs</code> <code>ArrayLike</code> <p>Array of shape [d1,d2,..,dn, k]</p> required <code>out_of_bound_value</code> <code>float</code> <p>optional float constant, defualt 0.</p> <code>0</code> <code>edge_indexing</code> <code>bool</code> <p>if True, the index for the top/left pixel is 0.5, otherwise 0. Default is False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>values</code> <code>Array</code> <p>[d1,d2,..,dn, ...], float</p>"},{"location":"api/ops/#lacss.ops.nms.non_max_suppression","title":"<code>non_max_suppression(scores, boxes, max_output_size, threshold=0.5, min_score=0, return_selection=False, similarity_func=None)</code>","text":"<p>non-maximum suppression for either bboxes or points.</p> <p>Assumption:</p> <pre><code>* The boxes/points are sorted by scores\n</code></pre> <p>The overal design of the algorithm is to handle boxes tile-by-tile:</p> <p>Parameters:</p> Name Type Description Default <code>scores</code> <code>ArrayLike</code> <p>[N]</p> required <code>boxes</code> <code>ArrayLike</code> <p>[N, C]  C=4 for boxes, C=2/3 for locations</p> required <code>max_output_size</code> <code>int</code> <p>a positive scalar integer</p> required <code>threshold</code> <code>float</code> <p>threshold of similarity score to supress</p> <code>0.5</code> <code>min_score</code> <code>float</code> <p>min score to be selected, default 0</p> <code>0</code> <code>return_selection</code> <code>bool</code> <p>whether also return the boolean indicator</p> <code>False</code> <code>similarity_func</code> <code>callable | None</code> <p>Optionally provide a custom callable to compute similarity score</p> <code>None</code> <p>Returns:</p> Name Type Description <code>nms_scores</code> <code>tuple[Array]</code> <p>[M].  M = max_output_size</p> <code>nms_proposals</code> <code>tuple[Array]</code> <p>[M, C].</p> <code>selection</code> <code>tuple[Array]</code> <p>[N] a boolean indicator of selection status of original input only if return_selection is True</p>"},{"location":"api/ops/#lacss.ops.patches.bboxes_of_patches","title":"<code>bboxes_of_patches(pred, threshold=0, *, image_shape=None, is2d=None)</code>","text":"<p>Compute the instance bboxes from model predictions</p> <p>Parameters:</p> Name Type Description Default <code>pred</code> <code>dict</code> <p>A model prediction dictionary:</p> required <code>threshold</code> <code>float</code> <p>for segmentation, default 0</p> <code>0</code> Keyward Args <p>image_shape: if not None, the boxes are clipped to be within the bound is2d: whether to force 2d output</p> <p>Returns:</p> Name Type Description <code>bboxes</code> <code>ndarray</code> <p>[n, 4] or [n, 6]</p>"},{"location":"api/ops/#lacss.ops.patches.coords_of_patches","title":"<code>coords_of_patches(preds, image_shape)</code>","text":"<p>get the zyx coordinates of segmentations</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <code>dict</code> <p>the model prediction dictionary</p> required <code>image_shape</code> <code>tuple[int, ...]</code> <p>the original input image shape. (H, W) for 2d and (D, H, W) for 3d</p> required <p>a tuple of (coordinates, boolean_masks)</p> Name Type Description <code>coordinates</code> <code>Array</code> <p>integer tensor of shape: (3,) + preds['segmentations'].shape</p> <code>boolan_masks</code> <code>Array</code> <p>boolean tensor indicating whether the coordinate is a real one of padding.</p>"},{"location":"api/ops/#lacss.ops.patches.crop_and_resize_patches","title":"<code>crop_and_resize_patches(pred, bboxes, *, target_shape=(48, 48), convert_logits=False)</code>","text":"<p>crop and rescale all instances to a target_size</p> <p>Parameters:</p> Name Type Description Default <code>pred</code> <code>dict</code> <p>model predictions</p> required <code>bboxes</code> <p>optionally supply bboxes for cropping</p> required <p>Keyward Args:     target_shape: output shape. usually a 3-tuple but can be a 2-tuple if input is a 2D image.     convert_logits: whether to convert the logits to probability</p> <p>Returns:</p> Type Description <p>Array [N] + target_shape.</p>"},{"location":"api/ops/#lacss.ops.patches.gather_patches","title":"<code>gather_patches(source, locations, patch_size, *, padding_value=0)</code>","text":"<p>gather patches from an array</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>ArrayLike</code> <p>[D1..dk, ...]</p> required <code>locations</code> <code>ArrayLike</code> <p>[N, k] top-left coords of the patches, negative (out-of-bound) is ok</p> required <code>patch_size</code> <code>int | tuple[int]</code> <p>size of the patch. </p> required <p>Keyward Args:     padding_value: value for out-of-bound locations</p> <p>Returns:</p> Type Description <p>N patches [N, d1..dk, ...]</p>"},{"location":"api/ops/#lacss.ops.patches.patches_to_label","title":"<code>patches_to_label(pred, input_size, *, mask=None, score_threshold=0.5, threshold=0)</code>","text":"<p>convert patch output to the image label.</p> <p>Parameters:</p> Name Type Description Default <code>pred</code> <code>DataDict</code> <p>A model prediction dictionary</p> required <code>input_size</code> <code>Shape</code> <p>shape of the input image. (H, W) or (D, H, W)</p> required <p>Keyward Args:     mask: boolean indicators masking out unwanted instances. Default is None (all cells)     score_threshold: otional, min_score to be included. Default is .5.     threshold: segmentation threshold.</p> <p>Returns:</p> Name Type Description <code>label</code> <code>Array</code> <p>of the dimension input_size</p>"},{"location":"api/ops/#lacss.ops.patches.rescale_patches","title":"<code>rescale_patches(pred, scale, *, transform_logits=True)</code>","text":"<p>Rescale/resize instance outputs in a sub-pixel accurate way. If the input image was rescaled, this function take care of rescaling the predictions to the orginal coodinates.</p> <p>Parameters:</p> Name Type Description Default <code>pred</code> <code>DataDict</code> <p>A model prediction dictionary</p> required <code>scale</code> <code>float</code> <p>The scaling value. The function does not take a noop shortcut even if scale is 1.</p> required <p>A tuple of three arrays</p> Name Type Description <code>patches</code> <code>Array</code> <p>a 3D array of the rescaled segmentation patches. The array shape should be different from the orignal patches in model predition.</p> <code>yy</code> <code>Array</code> <p>The y-coordinates of the patches in mesh-grid format</p> <code>xx</code> <code>Array</code> <p>The x-coordinates of the patches in mesh-grid format</p>"},{"location":"api/tracking/","title":"lacss.tracking","text":""},{"location":"api/tracking/#lacss.tracking.kalman.KalmanFilter","title":"<code>KalmanFilter</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>KalmanFilter Protocol definition</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KalmanFilter.initialize","title":"<code>initialize(measurement)</code>","text":"<p>Create track from unassociated measurement.</p> <p>Parameters:</p> Name Type Description Default <code>measurement</code> <p>data in measurement space</p> required <p>Returns:</p> Name Type Description <code>mean</code> <code>ndarray</code> <p>Unobserved velocities are initialized to 0 mean.</p> <code>cov</code> <code>ndarray</code> <p>covariance matrix (8x8 dimensional) of the new track.</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KalmanFilter.predict","title":"<code>predict(mean, covariance)</code>","text":"<p>Run Kalman filter prediction step.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <p>mean vector of the object state at the previous time step.</p> required <code>covariance</code> <p>The covariance matrix of the object state at the previous time step.</p> required <p>Returns:</p> Name Type Description <code>mean</code> <code>ndarray</code> <p>the mean vector of the predicted state</p> <code>cov</code> <code>ndarray</code> <p>the covariance matrix of the predicted</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KalmanFilter.update","title":"<code>update(mean, covariance, measurement)</code>","text":"<p>Run Kalman filter correction step.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <p>The predicted state's mean vector.</p> required <code>covariance</code> <p>The state's covariance matrix.</p> required <code>measurement</code> <p>The measurement vector</p> required <p>Returns:</p> Name Type Description <code>mean</code> <code>ndarray</code> <p>mean vector of the measurement-corrected state distribution.</p> <code>cov</code> <code>ndarray</code> <p>covariance matrix of the measurement-corrected state distribution.</p>"},{"location":"api/tracking/#lacss.tracking.kalman.ConstantVelocityKalmanFilter","title":"<code>ConstantVelocityKalmanFilter</code>","text":"<p>               Bases: <code>KalmanFilter</code></p> <p>A simple Kalman filter for tracking bounding boxes in image space.  The 8-dimensional state space</p> <pre><code>x, y, a, h, vx, vy, va, vh\n</code></pre> <p>contains the bounding box center position (x, y), aspect ratio a, height h, and their respective velocities.</p> <p>Object motion follows a constant velocity model. The bounding box location (x, y, a, h) is taken as direct observation of the state space (linear observation model).</p>"},{"location":"api/tracking/#lacss.tracking.kalman.ConstantVelocityKalmanFilter.__init__","title":"<code>__init__(*, std_weight_position=1 / 20, std_weight_velocity=1 / 160)</code>","text":"<p>Other Parameters:</p> Name Type Description <code>std_weight_position</code> <code>float</code> <p>Relative observation uncertainty.</p> <code>std_weight_velocity</code> <code>float</code> <p>Relative velocity uncertainty.</p>"},{"location":"api/tracking/#lacss.tracking.kalman.ConstantVelocityKalmanFilter.multi_predict","title":"<code>multi_predict(mean, covariance)</code>","text":"<p>vectorized version of the prediction step (Vectorized version).</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <p>Nx8 dimensional mean matrix of the object states at the previous time step.</p> required <code>covariance</code> <p>Nx8x8 dimensional covariance matrics of the object states at the previous time step.</p> required <p>Returns:</p> Name Type Description <code>mean</code> <code>ndarray</code> <p>the mean vector of the predicted state</p> <code>cov</code> <code>ndarray</code> <p>the covariance matrix of the predicted state</p>"},{"location":"api/tracking/#lacss.tracking.kalman.ConstantVelocityKalmanFilter.gating_distance","title":"<code>gating_distance(mean, covariance, measurements, only_position=False, metric='maha')</code>","text":"<p>Compute gating distance between state distribution and measurements.     A suitable distance threshold can be obtained from <code>chi2inv95</code>. If     <code>only_position</code> is False, the chi-square distribution has 4 degrees of     freedom, otherwise 2.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <p>Mean vector over the state distribution (8 dimensional).</p> required <code>covariance</code> <p>Covariance of the state distribution (8x8 dimensional).</p> required <code>measurements</code> <p>An Nx4 dimensional matrix of N measurements, each in format (x, y, a, h) where (x, y) is the bounding box center position, a the aspect ratio, and h the height.</p> required <code>only_position</code> <p>If True, distance computation is done with respect to the bounding box center position only.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>gating_distance</code> <code>ndarray</code> <p>an array of length N, where the i-th element contains the squared Mahalanobis distance between (mean, covariance) and <code>measurements[i]</code>.</p>"},{"location":"api/tracking/#lacss.tracking.kalman.ConstantVelocityKalmanFilter3D","title":"<code>ConstantVelocityKalmanFilter3D</code>","text":"<p>               Bases: <code>KalmanFilter</code></p> <p>A 3D Kalman filter for tracking 3D bounding boxes follows a constant velocity model.  The 8-dimensional state space are:</p> <pre><code>z, y, x, d, h, w, vz, vy, vx, vd, vh, vw\n</code></pre>"},{"location":"api/tracking/#lacss.tracking.kalman.ConstantVelocityKalmanFilter3D.__init__","title":"<code>__init__(*, std_weight_position=1 / 20, std_weight_velocity=1 / 160, z_scaling=1)</code>","text":"<p>Other Parameters:</p> Name Type Description <code>std_weight_position</code> <code>float</code> <p>Relative observation uncertainty.</p> <code>std_weight_velocity</code> <code>float</code> <p>Relative velocity uncertainty.</p> <code>z_scaling</code> <code>float</code> <p>relative pixel size along z-axis vs x-y-axis</p>"},{"location":"api/tracking/#lacss.tracking.kalman.ConstantVelocityKalmanFilter3D.multi_predict","title":"<code>multi_predict(mean, covariance)</code>","text":"<p>Vectorized Kalman filter prediction step.</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker","title":"<code>KTracker</code>","text":"<p>A stateful KalmanFilter tracker</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker.__init__","title":"<code>__init__(init_obs, frame_id, kf, *, data={})</code>","text":"<p>constructor</p> <p>Parameters:</p> Name Type Description Default <code>init_obs</code> <code>ArrayLike</code> <p>initial measurement space data</p> required <code>frame_id</code> <code>int</code> <p>the frame number</p> required <code>kf</code> <code>KalmanFilter</code> <p>a Kalman Filter following the KalmanFilter protocol</p> required <p>Other Parameters:</p> Name Type Description <code>data</code> <code>dict</code> <p>additional data of the observation that will be store</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker.predict","title":"<code>predict()</code>","text":"<p>Kalman filter prediction</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker.initialize","title":"<code>initialize()</code>","text":"<p>Initialze the track, so that it has a track id and a history object</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker.update","title":"<code>update(new_track)</code>","text":"<p>Kalman filter update step</p> <p>new_track: the new observation</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker.mark_lost","title":"<code>mark_lost(*, update_state=None)</code>","text":"<p>Mark the track as lost</p> <p>Other Parameters:</p> Name Type Description <code>update_state</code> <code>ArrayLike</code> <p>if not None, change the mean vector to this one</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker.mark_removed","title":"<code>mark_removed()</code>","text":"<p>Mark the track as removed</p>"},{"location":"api/tracking/#lacss.tracking.kalman.KTracker.assign","title":"<code>assign(tracks, dets, cost_matrix, threshold)</code>  <code>staticmethod</code>","text":"<p>perform MOT assigment</p> <p>Parameters:</p> Name Type Description Default <code>tracks</code> <code>Sequence[KTracker]</code> <p>current list of tracks of length M</p> required <code>dets</code> <code>Sequence[KTracker]</code> <p>list of new observations of length N</p> required <code>cost_matrix</code> <code>ArrayLike</code> <p>[M x N] cost matrix</p> required <code>threshold</code> <code>float</code> <p>max cost for linking</p> required <p>Returns:</p> Name Type Description <code>tracked</code> <code>Sequence[KTracker]</code> <p>list of tracks that are updated with new observations</p> <code>remaining_tracks</code> <code>Sequence[KTracker]</code> <p>list of tracks that did not find a suitable link</p> <code>remaining_dets</code> <code>Sequence[KTracker]</code> <p>the remaining detections that didn't get linked in.</p>"},{"location":"api/tracking/#lacss.tracking.ztracker.ZStackTracker","title":"<code>ZStackTracker</code>  <code>dataclass</code>","text":"<p>A special tracker for building 3d segmentation from a z-stack of 2d segmentations. It uses a kalman tracker of 2d boxes that assumes a fixed center location and tracking only the size changes.</p> <p>Attributes:</p> Name Type Description <code>score_thresh</code> <code>float</code> <p>score threshold for high-confidence detections</p> <code>nms_iou</code> <code>float</code> <p>filter the 2D results with non-max-supression</p> <code>cost_thresh</code> <code>float</code> <p>cost threshold for link assignment</p> <code>cost_thresh_secondary</code> <code>float</code> <p>cost threshold for link assignment of low confidence detections</p> <code>max_init_area</code> <code>float</code> <p>maximum segmentation area to be considered as the first slice of a cell </p> <code>max_time_lost</code> <code>int</code> <p>max consecutive missing slices  </p> <code>std_weight_position</code> <code>float</code> <p>kalman filter parameter. relative error for position </p> <code>std_weight_velocity</code> <code>float</code> <p>kalman filter parameter. relative error for velocity</p> <code>min_z_slices</code> <code>int</code> <p>minimal z slices needed to be considered a cell</p> <code>use_generalized_iou_loss</code> <code>bool</code> <p>whether to use generalized iou loss instead of simple iou_loss for linking cost</p>"},{"location":"api/tracking/#lacss.tracking.ztracker.ZStackTracker.update","title":"<code>update(tracks, dets, frame_id)</code>","text":"<p>Update the tracker with one frame</p> <p>Parameters:</p> Name Type Description Default <code>tracks</code> <code>Sequence[KTracker]</code> <p>a list of KTacker representing currently tracks cells</p> required <code>dets</code> <code>dict</code> <p>predictor output in bbox format</p> required <code>frame_id</code> <code>int</code> <p>current frame number</p> required <p>Returns:</p> Name Type Description <code>tracked_tracks</code> <code>list[KTracker]</code> <p>list of tracks that are active</p> <code>removed_tracks</code> <code>list[KTracker]</code> <p>list of tracks that are inactive</p>"},{"location":"api/tracking/#lacss.tracking.ztracker.ZStackTracker.finalize","title":"<code>finalize(tracks, *, fill_in_missing=True)</code>","text":"<p>Finalize step which compute scores and bboxes, and optionally fill in the missing segmentations. The aggregated score is the mean of the top-k 2d scores, where k is the min_z_slices. </p> <p>Parameters:</p> Name Type Description Default <code>tracks</code> <code>list[KTracker]</code> <p>list of tracks, each represent a cell in 3d</p> required <p>Other Parameters:</p> Name Type Description <code>fill_in_missing</code> <code>bool</code> <p>whether try to generate segmentations for missing slices</p> <p>Returns:</p> Type Description <code>list[KTracker]</code> <p>list of tracks will \"score\", \"bbox\" fields.</p>"},{"location":"api/tracking/#lacss.tracking.ztracker.ZStackTracker.render_label","title":"<code>render_label(tracks, img3d_shape)</code>  <code>staticmethod</code>","text":"<p>create 3d label from tracking results</p> <p>Parameters:</p> Name Type Description Default <code>tracks</code> <code>list[KTracker]</code> <p>list of tracks</p> required <code>img3d_shape</code> <code>Sequence[int]</code> <p>tuple of (D, H, W)</p> required <p>Returns:</p> Name Type Description <code>label</code> <code>ndarray</code> <p>array of shape (D, H, W)</p>"}]}