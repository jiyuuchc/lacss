{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LACSS Demo\n",
        "This is a simple demo of semi-supervised LACSS training. We will train a model using the neuroblastoma dataset from the Cell Image Library. \n"
      ],
      "metadata": {
        "id": "9VXmgZ3eKTvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jiyuuchc/lacss.git\n",
        "!wget https://data.mendeley.com/api/datasets/894mmsd9nj/draft/files/568e524f-9a95-45a6-9f80-3619969c2a37"
      ],
      "metadata": {
        "id": "3JneiMlWJhO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA9hNjQkHzb3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from os.path import join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches\n",
        "import cv2\n",
        "from skimage.color import label2rgb\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "layers = tf.keras.layers\n",
        "\n",
        "sys.path.append('/content/lacss/')\n",
        "import lacss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the data pipeline"
      ],
      "metadata": {
        "id": "Au_e9rWpKxD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "data_path = 'data'\n",
        "with zipfile.ZipFile('cil.zip', \"r\") as f:\n",
        "    f.extractall(data_path)\n",
        "\n",
        "imgfiles = [join(data_path, 'train', f'{k:03d}_img.png') for k in range(89)]\n",
        "maskfiles = [join(data_path, 'train', f'{k:03d}_masks.png') for k in range(89)]\n",
        "\n",
        "ds_train =lacss.data.dataset_from_img_mask_pairs(imgfiles, maskfiles)"
      ],
      "metadata": {
        "id": "MXHG3NzThrgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The orginal dataset contains the full segmentation annotation, which we will not use\n",
        "# Therefore we setup a data parser to remove the extra annotation\n",
        "\n",
        "def train_parser(x):\n",
        "    del x['mask_indices']\n",
        "    del x['bboxes']\n",
        "\n",
        "    # the parser function in the lacss code apply simple data augmentation e.g. flipping and resizing\n",
        "    x = lacss.data.parse_train_data_func(x, size_jitter=(0.9, 1.1))\n",
        "\n",
        "    return x\n",
        "\n",
        "ds_train = ds_train.map(train_parser)\n",
        "\n",
        "# just in case, we remove samples without any cells in it\n",
        "ds_train = ds_train.filter(lambda x : tf.shape(x['locations'])[0]>0).repeat()\n",
        "\n",
        "# We will use ragged batching, and set batch_size = 1 so it will run on any GPU\n",
        "ds_train = ds_train.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=1))\n"
      ],
      "metadata": {
        "id": "UV0z8HWpK7Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model configuration and training"
      ],
      "metadata": {
        "id": "QCwNroloLqPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the resnet50 backbone, we also disabled auxnet by setting the last loss_weight to 0\n",
        "model = lacss.models.LacssModel(\n",
        "    backbone='resnet_att', \n",
        "    train_supervised=False,\n",
        "    instance_crop_size=128,\n",
        "    loss_weights=(1.0, 1.0, 1.0, 0.0),\n",
        "    )\n",
        "\n",
        "# Use Adam at default setting\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "# train a bunch of steps\n",
        "model.fit(ds_train, epochs=15, steps_per_epoch=1000)"
      ],
      "metadata": {
        "id": "0-YI8yCdDhL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the results on the validation set "
      ],
      "metadata": {
        "id": "MySmdwNuNbFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiMt_ou-6FsK"
      },
      "outputs": [],
      "source": [
        "# load the validation dataset\n",
        "imgfiles = [join(data_path, 'test', f'{k:03d}_img.png') for k in range(11)]\n",
        "maskfiles = [join(data_path, 'test', f'{k:03d}_masks.png') for k in range(11)]\n",
        "\n",
        "ds_val =lacss.data.dataset_from_img_mask_pairs(imgfiles, maskfiles)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the 3rd image in the validation set\n",
        "for x in ds_val.skip(2).take(1):\n",
        "    pass\n",
        "x = lacss.data.parse_test_data_func(x) # this pad the input image so that ResNet won't complain\n",
        "y = model(x)\n",
        "\n",
        "# adjust the contrast of input image for better display\n",
        "input_img = (x['image'] + 0.5)/6\n",
        "input_img = (input_img.numpy()* 255).astype('uint8')\n",
        "\n",
        "# we will use the RGB label format to dislay the ground truth\n",
        "gt_label = tf.scatter_nd(x['mask_indices'].values, x['mask_indices'].value_rowids() + 1, x['image'].shape[:2])\n",
        "gt_label_rgb = label2rgb(gt_label.numpy(), bg_label=0)"
      ],
      "metadata": {
        "id": "5w4RR4i1NpoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add contours of model predictions on both input image and ground truth label\n",
        "coords = y['instance_coords'][0][:110, ...]\n",
        "patches = y['instance_output'][0][:110,:,:,0]\n",
        "n_patches, patch_size, _ = patches.shape\n",
        "page_n = tf.tile(tf.range(n_patches)[:,None,None,None], [1, patch_size, patch_size, 1])\n",
        "coords_ext = tf.concat([page_n, coords], axis=-1)\n",
        "stack_shape = [n_patches,] + x['image'].shape[:2].as_list()\n",
        "img_stack = tf.scatter_nd(coords_ext, patches, stack_shape)\n",
        "img_stack = (img_stack.numpy() >= 0.5).astype('uint8')\n",
        "for page in img_stack:\n",
        "    contours, _ = cv2.findContours(page, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(input_img, contours, -1, (128,128,128), 1, cv2.LINE_AA)\n",
        "    cv2.drawContours(gt_label_rgb, contours, -1, (64,64,64), 1, cv2.LINE_AA)\n",
        "\n",
        "# now display the results\n",
        "fig,ax=plt.subplots(1, 2, figsize=(15,10))\n",
        "ax[0].imshow(input_img)\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(gt_label_rgb)\n",
        "ax[1].axis('off')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "FtLfCdw1OqCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C065CbgkvXm2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}