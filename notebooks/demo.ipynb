{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VXmgZ3eKTvc"
      },
      "source": [
        "## LACSS Demo\n",
        "This is a simple demo of semi-supervised LACSS training. We will train a model using the neuroblastoma dataset from the Cell Image Library. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JneiMlWJhO2"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/jiyuuchc/lacss.git\n",
        "!wget https://data.mendeley.com/public-files/datasets/894mmsd9nj/files/568e524f-9a95-45a6-9f80-3619969c2a37/file_downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA9hNjQkHzb3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from os.path import join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.color import label2rgb\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "layers = tf.keras.layers\n",
        "\n",
        "sys.path.append('/content/lacss/')\n",
        "import lacss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au_e9rWpKxD7"
      },
      "source": [
        "### Setting up the data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXHG3NzThrgF"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "data_path = 'data'\n",
        "with zipfile.ZipFile('file_downloaded', \"r\") as f:\n",
        "    f.extractall(data_path)\n",
        "\n",
        "imgfiles = [join(data_path, 'train', f'{k:03d}_img.png') for k in range(89)]\n",
        "maskfiles = [join(data_path, 'train', f'{k:03d}_masks.png') for k in range(89)]\n",
        "\n",
        "ds_train =lacss.data.dataset_from_img_mask_pairs(imgfiles, maskfiles)\n",
        "\n",
        "# load the validation dataset\n",
        "imgfiles = [join(data_path, 'test', f'{k:03d}_img.png') for k in range(11)]\n",
        "maskfiles = [join(data_path, 'test', f'{k:03d}_masks.png') for k in range(11)]\n",
        "\n",
        "ds_val =lacss.data.dataset_from_img_mask_pairs(imgfiles, maskfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV0z8HWpK7Qx"
      },
      "outputs": [],
      "source": [
        "# The orginal dataset contains the full segmentation annotation, which we will not use\n",
        "# Therefore we setup a data parser to remove the extra annotation\n",
        "\n",
        "def train_parser(x):\n",
        "    del x['mask_indices']\n",
        "    del x['bboxes']\n",
        "\n",
        "    # the parser function in the lacss code apply simple data augmentation e.g. flipping and resizing\n",
        "    x = lacss.data.parse_train_data_func(x, size_jitter=(0.9, 1.1))\n",
        "\n",
        "    if tf.random.uniform([]) >=0.5:\n",
        "         x['image'] = tf.image.transpose(x['image'])\n",
        "         x['binary_mask'] = tf.image.transpose(x['binary_mask'])\n",
        "         x['locations'] = x['locations'][:,::-1]\n",
        "\n",
        "    return x\n",
        "\n",
        "ds_train = ds_train.map(train_parser)\n",
        "\n",
        "# just in case, we remove samples without any cells in it\n",
        "ds_train = ds_train.filter(lambda x : tf.shape(x['locations'])[0]>0).repeat()\n",
        "\n",
        "# We will use ragged batching, and set batch_size = 1 so it will run on any GPU\n",
        "ds_train = ds_train.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCwNroloLqPv"
      },
      "source": [
        "### Model configuration and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-YI8yCdDhL1"
      },
      "outputs": [],
      "source": [
        "# use the resnet50 backbone, we also disabled auxnet by setting the last loss_weight to 0\n",
        "model = lacss.models.LacssModel(\n",
        "    backbone='resnet_att', \n",
        "    train_supervised=False,\n",
        "    instance_crop_size=128,\n",
        "    loss_weights=(1.0, 1.0, 1.0, 0.0),\n",
        "    )\n",
        "\n",
        "# Use Adam at default setting\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "def evaluation(epoch, logs):\n",
        "    mask_AP = lacss.metrics.MaskMeanAP([.5])\n",
        "    for x in tqdm(ds_val):\n",
        "        y = model(lacss.data.parse_test_data_func(x))\n",
        "        scores = y['pred_location_scores'][0]\n",
        "        patches = y['instance_output'][0]\n",
        "        coords = y['instance_coords'][0]\n",
        "        pred_bboxes = lacss.ops.bboxes_of_patches(patches, coords)\n",
        "        pred = (patches, coords, pred_bboxes)\n",
        "\n",
        "        gt_bboxes=x['bboxes']\n",
        "        gt_mi=x['mask_indices']\n",
        "        gt = (gt_mi,gt_bboxes)\n",
        "\n",
        "        mask_AP.update_state(gt, pred, scores)\n",
        "\n",
        "    ap = mask_AP.result()[0]\n",
        "    print(f'maskAP50: {ap}')\n",
        "\n",
        "callbacks = [tf.keras.callbacks.LambdaCallback(on_epoch_end=evaluation),]\n",
        "\n",
        "# train a bunch of steps\n",
        "model.fit(ds_train, epochs=30, callbacks=callbacks, steps_per_epoch=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MySmdwNuNbFD"
      },
      "source": [
        "### Display the results on the validation set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w4RR4i1NpoJ"
      },
      "outputs": [],
      "source": [
        "# Let's check the image in the validation set\n",
        "for x in ds_val.take(1):\n",
        "    pass\n",
        "x = lacss.data.parse_test_data_func(x) # this pad the input image so that ResNet won't complain\n",
        "y = model(x)\n",
        "\n",
        "# adjust the contrast of input image for better display\n",
        "input_img = (x['image'] + 0.5)/6\n",
        "input_img = (input_img.numpy()* 255).astype('uint8')\n",
        "\n",
        "# we will use the RGB label format to dislay the ground truth\n",
        "gt_label = tf.scatter_nd(x['mask_indices'].values, x['mask_indices'].value_rowids() + 1, x['image'].shape[:2])\n",
        "gt_label_rgb = label2rgb(gt_label.numpy(), bg_label=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtLfCdw1OqCN"
      },
      "outputs": [],
      "source": [
        "# add contours of model predictions on both input image and ground truth label\n",
        "coords = y['instance_coords'][0][:110, ...]\n",
        "patches = y['instance_output'][0][:110,:,:,0]\n",
        "n_patches, patch_size, _ = patches.shape\n",
        "page_n = tf.tile(tf.range(n_patches)[:,None,None,None], [1, patch_size, patch_size, 1])\n",
        "coords_ext = tf.concat([page_n, coords], axis=-1)\n",
        "stack_shape = [n_patches,] + x['image'].shape[:2].as_list()\n",
        "img_stack = tf.scatter_nd(coords_ext, patches, stack_shape)\n",
        "img_stack = (img_stack.numpy() >= 0.5).astype('uint8')\n",
        "for page in img_stack:\n",
        "    contours, _ = cv2.findContours(page, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(input_img, contours, -1, (128,128,128), 1, cv2.LINE_AA)\n",
        "    cv2.drawContours(gt_label_rgb, contours, -1, (64,64,64), 1, cv2.LINE_AA)\n",
        "\n",
        "# now display the results\n",
        "fig,ax=plt.subplots(1, 2, figsize=(15,10))\n",
        "ax[0].imshow(input_img)\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(gt_label_rgb)\n",
        "ax[1].axis('off')\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C065CbgkvXm2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f43c0735a9c6918b4634f66b597319e595bcd11c7e5a7d407e81c02c94a91224"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
