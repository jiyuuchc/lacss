{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPeMUSq-jrmY"
   },
   "source": [
    "# LACSS Inference Demo\n",
    "\n",
    "This is a small notebook demonstrating the workflow of applying an LACSS model to make segmentation prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAsPHCLIkPzX"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLbgbwxti6bO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/jiyuuchc/lacss@lacss1\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "from lacss.deploy import Predictor, model_urls\n",
    "from lacss.utils import show_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB2DCgOplObO"
   },
   "source": [
    "## Load a pre-trained model\n",
    "\n",
    "Here we load a model pre-trained on the [tissuenet](https://datasets.deepcell.org/) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xg0ja_TkkpOl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = Predictor(model_urls[\"cnsp4-fl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPYmZ-O9mn-x"
   },
   "source": [
    "## Also download some image data\n",
    "\n",
    "We will download some microscopy images from the [Cell Image Library](http://www.cellimagelibrary.org/home) collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Hsex1ShmR_T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -c https://data.mendeley.com/public-files/datasets/894mmsd9nj/files/568e524f-9a95-45a6-9f80-3619969c2a37/file_downloaded -O images.zip\n",
    "\n",
    "import zipfile\n",
    "\n",
    "data_path = 'image_data'\n",
    "with zipfile.ZipFile('images.zip', \"r\") as f:\n",
    "    f.extractall(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g1mb9D9nZEp"
   },
   "source": [
    "## Make a prdiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Jt1ThPcnbAo"
   },
   "outputs": [],
   "source": [
    "image = imageio.imread(\"image_data/test/000_img.png\")\n",
    "gt = imageio.imread(\"image_data/test/000_masks.png\")\n",
    "\n",
    "pred = predictor.predict(image.astype(\"float32\"))[\"pred_label\"]\n",
    "\n",
    "# the default model outputs are JAX arrays. It is more convenient \n",
    "# to use a numpy array for downstream analysis / visulization\n",
    "pred = np.asarray(pred)\n",
    "\n",
    "show_images([\n",
    "    image,\n",
    "    label2rgb(pred, bg_label=0),\n",
    "    label2rgb(gt, bg_label=0),\n",
    "])\n",
    "\n",
    "titles = ['Input', \"Prediction\", \"Ground Truth\"]\n",
    "[ax.set_title(title) for ax, title in zip(plt.gcf().get_axes(), titles)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKeJy9rcvsGm"
   },
   "source": [
    "You may notice that the last part of the code is running quite slowly. This is because LACSS is model based on [JAX](https://jax.readthedocs.io/en/latest/) framework, which performs **just-in-time compilation** of the model the first time we run it. This will take some time, but only happens on the first run.\n",
    "\n",
    "In addition, the inferencen result is BAD! Why? Well, the model was trained on a tisuenet dataset, but the image we are analyzing is from an unrelated dataset, which has different channel organization and different pixel value normalization. We can improve the results by rearrange the data to match the orginal training data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8fqDK1Onl8G"
   },
   "outputs": [],
   "source": [
    "image_rearranged = image[..., (1,0,2)] / 255.0\n",
    "\n",
    "pred = predictor.predict(image_rearranged)[\"pred_label\"]\n",
    "pred = np.asarray(pred) \n",
    "\n",
    "show_images([\n",
    "    image,\n",
    "    label2rgb(pred, bg_label=0),\n",
    "    label2rgb(gt, bg_label=0),\n",
    "])\n",
    "\n",
    "titles = ['Input', \"Prediction\", \"Ground Truth\"]\n",
    "[ax.set_title(title) for ax, title in zip(plt.gcf().get_axes(), titles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZagJ4GAxz8N"
   },
   "source": [
    "Ok, much better.\n",
    "\n",
    "It is still not good enough though. The remaining inaccuracies reflect the **domain shift** between the training data and the inference data. we can further improve the results by re-training on the new dataset. Check the [training demos](https://www.github.com/jiyuuchc/lacss_jax) to see how to do that."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
