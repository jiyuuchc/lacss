{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kks5J-TD8-Bh"
   },
   "source": [
    "# LACSS Point-supervised Training Demo\n",
    "\n",
    "The demo will train a model to segment microscopy images of cells, using only point label.\n",
    "\n",
    " * The point label was produced automatically from DAPI images\n",
    "\n",
    "We will go through these steps:\n",
    "\n",
    "- Setup the data pipeline\n",
    "\n",
    "- Initialize a model trainer\n",
    "\n",
    "- Perform model training\n",
    "\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp1Y6zHl9ddY"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ivh9LzC89QK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/jiyuuchc/lacss@lacss1\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import json\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from flax.core.frozen_dict import freeze, unfreeze\n",
    "\n",
    "import lacss.data\n",
    "from lacss.train import LacssTrainer, VMapped, TFDatasetAdapter\n",
    "from lacss.ops import patches_to_label\n",
    "from lacss.utils import show_images, load_from_pretrained\n",
    "from lacss.deploy import model_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr0QliBABDOh"
   },
   "source": [
    "## Data pipeline\n",
    "\n",
    "Lacss expect training data from a python generator that produces the following data:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"image\": ndarray[B, W, H, C],\n",
    "  \"gt_locations\": ndarray[B, N, 2]\n",
    "}\n",
    "```\n",
    "\n",
    "Here we will set up the data pipeline using tensorflow.dataset library, which has many useful utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rqdox1oOccv4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget -c https://data.mendeley.com/public-files/datasets/89s3ymz5wn/files/f976856c-08c5-4bba-85a7-3881e0593115/file_downloaded -O A431.zip\n",
    "\n",
    "import zipfile\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "data_path = Path('image_data')\n",
    "with zipfile.ZipFile('A431.zip', \"r\") as f:\n",
    "    f.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3bSK8QDEKlM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "def parser(data):\n",
    "    # build-in data augmentation function\n",
    "    data[\"image\"] = tf.image.per_image_standardization(data[\"image\"])\n",
    "    data = lacss.data.random_resize(data, scaling=[.8, 1.2])\n",
    "    data = lacss.data.random_crop_or_pad(data, target_size=[512,512])\n",
    "\n",
    "    return dict(\n",
    "      image = data['image'],\n",
    "      gt_locations = data[\"centroids\"],\n",
    "    )\n",
    "\n",
    "# create a tensowflow dataset from the files on disk\n",
    "ds = (\n",
    "    lacss.data.dataset_from_simple_annotations(\n",
    "        data_path/\"train.json\",\n",
    "        data_path/\"train\",\n",
    "        image_shape=[None, None, 1]\n",
    "    )\n",
    "    .map(parser)\n",
    "    .repeat()\n",
    "    .padded_batch(\n",
    "        batch_size,\n",
    "        padded_shapes=dict(\n",
    "            image=[512,512,1],\n",
    "            gt_locations=[768,2],\n",
    "        ),\n",
    "        padding_values=-1.0,\n",
    "    )\n",
    "    .prefetch(1)\n",
    ")\n",
    "\n",
    "# make sure the dataset has the correct element structure\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show an example of the training data\n",
    "\n",
    "data = next(iter(ds))\n",
    "img = data['image'][0]\n",
    "locations = data['gt_locations'][0]\n",
    "\n",
    "show_images([\n",
    "    img,\n",
    "    np.zeros_like(img),\n",
    "])\n",
    "ax = plt.gcf().get_axes()\n",
    "ax[0].set_title(\"Image\")\n",
    "for pos in locations:\n",
    "    c = Circle((pos[1], pos[0]), radius=2, edgecolor='white')\n",
    "    ax[1].add_patch(c)\n",
    "ax[1].set_title(\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GESuO6zM9tso"
   },
   "source": [
    "## Initialize a trainer\n",
    "\n",
    "We will use transfer learning by starting from a pre-trained model. Transfer learning is generally beneficial even if the orginal model was trained on data that looks very different from the current images.\n",
    "\n",
    "The main training interface here is ```LacssTrainer```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2mp9sJM-Tul",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "# This model was trained on bright field microscopy images (LIVECell dataset)\n",
    "# This will be serve as the principal model and retrained with the new data\n",
    "!wget -c {model_urls[\"cnsp4-bf\"]} -O cnsp4_bf\n",
    "pretrained_module, pretrained_params = load_from_pretrained(\"cnsp4_bf\")\n",
    "principal_cfg = pretrained_module.get_config()\n",
    "\n",
    "collaborator_cfg = {} # use default config for collaborator model\n",
    "\n",
    "trainer = LacssTrainer(\n",
    "    principal_cfg,\n",
    "    collaborator_cfg,\n",
    "    strategy=VMapped,\n",
    ")\n",
    "\n",
    "# create random weights\n",
    "params = trainer.get_init_params(TFDatasetAdapter(ds))\n",
    "\n",
    "# Now merge with the pre-trained weights\n",
    "params['principal'] = pretrained_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"---Current model configuration---\")\n",
    "pprint(\n",
    "    trainer.model.principal.get_config(),\n",
    "    sort_dicts=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5qcbxs5aomk"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09jrmOyjaoAs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_steps = 12000\n",
    "validation_interval = 3000\n",
    "\n",
    "trainer.do_training(\n",
    "    TFDatasetAdapter(ds),\n",
    "    n_steps = n_steps,\n",
    "    validation_interval = validation_interval,\n",
    "    init_vars = dict(params=params),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_tBseBbc-mw"
   },
   "source": [
    "## Visualize  the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qOX43ZnYyX-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "image = imageio.imread(data_path/'test'/'img_0001.tif')\n",
    "gt = imageio.imread(data_path/'test'/'masks_0001.tif')\n",
    "img = image - image.mean()\n",
    "img /= img.std()\n",
    "img = img[..., None]\n",
    "\n",
    "# prediction\n",
    "model_output = trainer.model.apply(\n",
    "    dict(params=trainer.parameters),\n",
    "    image = img,\n",
    ")\n",
    "pred = patches_to_label(\n",
    "    model_output, \n",
    "    input_size=img.shape[:2]\n",
    ")\n",
    "pred = np.asarray(pred)\n",
    "\n",
    "# display\n",
    "show_images([\n",
    "    img,\n",
    "    pred,\n",
    "    label2rgb(gt, bg_label=0),\n",
    "])\n",
    "titles = ['Input', \"Prediction\", \"Ground Truth\"]\n",
    "[ax.set_title(title) for ax, title in zip(plt.gcf().get_axes(), titles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's more?\n",
    "\n",
    "- You can train for more steps\n",
    "- You can perform quantitative evaluation\n",
    "- You can incorporate validation and checkpointing into the training loop\n",
    "- You can export the trained model\n",
    "\n",
    "Check the [documentation](https://jiyuuchc.github.io/lacss/api/deploy/) for details."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
