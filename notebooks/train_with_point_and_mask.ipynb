{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kks5J-TD8-Bh"
   },
   "source": [
    "# LACSS Weakly-supervised Training Demo\n",
    "\n",
    "The demo will train a model to segment microscopy images of cells, using point label + mask label.\n",
    "\n",
    " * The point label was produced automatically from DAPI images\n",
    "\n",
    " * The image-level mask label was produced manually.\n",
    "\n",
    "We will go through these steps:\n",
    "\n",
    "- Setup the data pipeline\n",
    "\n",
    "- Initialize a model trainer\n",
    "\n",
    "- Perform model training\n",
    "\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp1Y6zHl9ddY"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ivh9LzC89QK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install lacss\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from flax.core.frozen_dict import freeze, unfreeze\n",
    "\n",
    "import lacss.data\n",
    "from lacss.train import LacssTrainer, VMapped, TFDatasetAdapter\n",
    "from lacss.ops import patches_to_label\n",
    "from lacss.utils import show_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr0QliBABDOh"
   },
   "source": [
    "## Data pipeline\n",
    "\n",
    "Lacss expect training data from a python generator that produces the following data:\n",
    "\n",
    "```\n",
    "x_data, y_data = (\n",
    "  {\n",
    "    \"image\": ndarray[B, W, H, C],\n",
    "    \"gt_locations\": ndarray[B, N, 2]\n",
    "  },\n",
    "  {\n",
    "    \"gt_image_mask\": ndarray[B, W, H]\n",
    "  }\n",
    ")\n",
    "```\n",
    "\n",
    "Here we will set up the data pipeline using tensorflow.dataset library, which has many useful utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rqdox1oOccv4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget -c https://data.mendeley.com/public-files/datasets/89s3ymz5wn/files/f976856c-08c5-4bba-85a7-3881e0593115/file_downloaded -O A431.zip\n",
    "\n",
    "import zipfile\n",
    "\n",
    "data_path = Path('image_data')\n",
    "with zipfile.ZipFile('A431.zip', \"r\") as f:\n",
    "    f.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3bSK8QDEKlM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "def parser(data):\n",
    "    # build-in data augmentation function\n",
    "    data = lacss.data.random_resize(data, scaling=[0.8, 1.2])\n",
    "    data = lacss.data.random_crop_or_pad(data, target_size=[512,512])\n",
    "\n",
    "    # It is important to pad the locations tensor so that all elements of the dataset are of the same shape\n",
    "    locations = data['centroids']\n",
    "    n_pad = 768 - len(locations)\n",
    "    locations = tf.pad(locations, [[0, n_pad], [0,0]], constant_values=-1)\n",
    "\n",
    "    return (\n",
    "        dict(\n",
    "            image = tf.ensure_shape(data['image'], [512,512,1]),\n",
    "            gt_locations = tf.ensure_shape(locations, [768,2]) \n",
    "        ),\n",
    "        dict(\n",
    "            gt_image_mask = data['image_mask'],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# create a tensowflow dataset from the files on disk\n",
    "ds = (\n",
    "    lacss.data.dataset_from_simple_annotations(\n",
    "        data_path/\"train.json\",\n",
    "        data_path/\"train\",\n",
    "        image_shape=[512, 512, 1]\n",
    "    )\n",
    "    .map(parser)\n",
    "    .repeat()\n",
    "    .batch(batch_size)\n",
    "    .prefetch(10)\n",
    ")\n",
    "\n",
    "# make sure the dataset has the correct element structure\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ4ibyHzEUO7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show an example of the training data\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "x_data, y_data = next(ds.as_numpy_iterator())\n",
    "img = x_data['image'][0]\n",
    "locations = x_data['gt_locations'][0]\n",
    "mask = y_data['gt_image_mask'][0]\n",
    "\n",
    "show_images([\n",
    "    img,\n",
    "    np.stack([mask]*3, axis=-1) * 0.5,\n",
    "])\n",
    "\n",
    "ax = plt.gcf().get_axes()\n",
    "ax[0].set_title(\"Image\")\n",
    "for pos in locations:\n",
    "    c = Circle((pos[1], pos[0]), radius=2, edgecolor='white')\n",
    "    ax[1].add_patch(c)\n",
    "ax[1].set_title(\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GESuO6zM9tso"
   },
   "source": [
    "## Initialize a trainer\n",
    "\n",
    "The idea is to co-train two models: a principal model and a collaborator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2mp9sJM-Tul",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pp\n",
    "\n",
    "# use default model setting\n",
    "principal_cfg = {}\n",
    "collaborator_cfg = {} \n",
    "\n",
    "trainer = LacssTrainer(\n",
    "    principal_cfg, \n",
    "    collaborator_cfg, \n",
    "    seed=1234,\n",
    "    strategy=VMapped,\n",
    ")\n",
    "\n",
    "print(\"---Current model configuration---\")\n",
    "pp(\n",
    "    trainer.model.principal,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5qcbxs5aomk"
   },
   "source": [
    "## Training\n",
    "\n",
    "Trainer.train() function returns an iterator, stepping through which will drive the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09jrmOyjaoAs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_steps = 9000\n",
    "validation_interval = 3000\n",
    "\n",
    "trainer.do_training(\n",
    "  TFDatasetAdapter(ds),\n",
    "  n_steps = n_steps,\n",
    "  validation_interval = validation_interval,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_tBseBbc-mw"
   },
   "source": [
    "## Visualize  the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qOX43ZnYyX-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "img = imageio.imread(data_path/'test'/'img_0001.tif')\n",
    "gt = imageio.imread(data_path/'test'/'masks_0001.tif')\n",
    "img = img[..., None] / 255\n",
    "\n",
    "# prediction\n",
    "model_output = trainer.model.apply(\n",
    "    dict(params=trainer.parameters),\n",
    "    image = img,\n",
    ")\n",
    "pred = patches_to_label(model_output, input_size=img.shape[:2])\n",
    "pred = np.asarray(pred)\n",
    "\n",
    "lacss.utils.show_images([\n",
    "    img,\n",
    "    label2rgb(pred, bg_label=0),\n",
    "    label2rgb(gt, bg_label=0),\n",
    "])\n",
    "titles = ['Input', \"Prediction\", \"Ground Truth\"]\n",
    "[ax.set_title(title) for ax, title in zip(plt.gcf().get_axes(), titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-FpYFh3Tl6E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
